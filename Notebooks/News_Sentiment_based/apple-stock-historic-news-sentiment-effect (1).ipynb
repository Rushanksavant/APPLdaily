{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport re\nimport nltk\nfrom nltk.corpus import stopwords # importing 'stopwords' to this notebook\nfrom nltk.stem.porter import PorterStemmer ## stemming of words\n\nimport joblib","execution_count":1,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data= pd.read_csv('../input/stock-price-and-news-realted-to-it/AppleNewsStock.csv')\ndata.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"         Date       Open       High        Low      Close  Adj Close  \\\n0  2006-12-01  13.114285  13.190000  12.871428  91.320000  13.045714   \n1  2006-12-04  13.125714  13.150000  12.928572  91.120003  13.017143   \n2  2006-12-05  13.092857  13.190000  12.981428  91.269997  13.038571   \n3  2006-12-06  12.948571  13.055715  12.810000  89.830002  12.832857   \n4  2006-12-07  12.861428  12.928572  12.414286  87.040001  12.434286   \n\n      Volume                                               News  \n0  198769900  WHAT'S ON TONIGHT : 8 P.M. (TLC) ASHLEY JUDD A...  \n1  177384200  More on Housing Prices : The broadest governme...  \n2  165709600                                                NaN  \n3  159546100  Honoring R.W. Apple in Words and Food : About ...  \n4  251206900  Homebuilders, and Worries Over Jobs, Lead a De...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n      <th>News</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2006-12-01</td>\n      <td>13.114285</td>\n      <td>13.190000</td>\n      <td>12.871428</td>\n      <td>91.320000</td>\n      <td>13.045714</td>\n      <td>198769900</td>\n      <td>WHAT'S ON TONIGHT : 8 P.M. (TLC) ASHLEY JUDD A...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2006-12-04</td>\n      <td>13.125714</td>\n      <td>13.150000</td>\n      <td>12.928572</td>\n      <td>91.120003</td>\n      <td>13.017143</td>\n      <td>177384200</td>\n      <td>More on Housing Prices : The broadest governme...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2006-12-05</td>\n      <td>13.092857</td>\n      <td>13.190000</td>\n      <td>12.981428</td>\n      <td>91.269997</td>\n      <td>13.038571</td>\n      <td>165709600</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2006-12-06</td>\n      <td>12.948571</td>\n      <td>13.055715</td>\n      <td>12.810000</td>\n      <td>89.830002</td>\n      <td>12.832857</td>\n      <td>159546100</td>\n      <td>Honoring R.W. Apple in Words and Food : About ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2006-12-07</td>\n      <td>12.861428</td>\n      <td>12.928572</td>\n      <td>12.414286</td>\n      <td>87.040001</td>\n      <td>12.434286</td>\n      <td>251206900</td>\n      <td>Homebuilders, and Worries Over Jobs, Lead a De...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Data Prepration"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assigning labels to the entries\nlabel_list=[]\nfor i in range(1, len(data)):\n    if data['Adj Close'][i] - data['Adj Close'][i-1]>= 0:\n        label_list.append(1)\n    else:\n        label_list.append(0)\ndata1= data.iloc[1: ]\ndata1.insert(2, \"Label\", label_list)\n\ndata_new= data1[[\"Label\", \"News\", \"Open\"]] # Making data with just news and labels\n\n\n# Adding previous adj close\nprevious_adj_close= []\nfor i in range(1, len(data)):\n    previous_adj_close.append(data[\"Adj Close\"][i])\n    \ndata_new.insert(3, \"Pre Adj Close\", previous_adj_close)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(data_new)\n# Setting New Index for data\ndata_new= data_new.set_index(i for i in range(0, len(data_new)))","execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"      Label                                               News        Open  \\\n1         0  More on Housing Prices : The broadest governme...   13.125714   \n2         1                                                NaN   13.092857   \n3         0  Honoring R.W. Apple in Words and Food : About ...   12.948571   \n4         0  Homebuilders, and Worries Over Jobs, Lead a De...   12.861428   \n5         1  Homebuilders, and Worries Over Jobs, Lead a De...   12.461429   \n...     ...                                                ...         ...   \n2512      0                                                NaN  111.360001   \n2513      1  Fighting iOS Calendar Spam : Unsolicited invit...  111.129997   \n2514      0                                                NaN  111.430000   \n2515      0                                                NaN  110.779999   \n2516      0                                                NaN  111.599998   \n\n      Pre Adj Close  \n1         13.017143  \n2         13.038571  \n3         12.832857  \n4         12.434286  \n5         12.608571  \n...             ...  \n2512     111.230003  \n2513     111.790001  \n2514     111.570000  \n2515     111.459999  \n2516     110.519997  \n\n[2516 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>News</th>\n      <th>Open</th>\n      <th>Pre Adj Close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>More on Housing Prices : The broadest governme...</td>\n      <td>13.125714</td>\n      <td>13.017143</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>13.092857</td>\n      <td>13.038571</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Honoring R.W. Apple in Words and Food : About ...</td>\n      <td>12.948571</td>\n      <td>12.832857</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Homebuilders, and Worries Over Jobs, Lead a De...</td>\n      <td>12.861428</td>\n      <td>12.434286</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>Homebuilders, and Worries Over Jobs, Lead a De...</td>\n      <td>12.461429</td>\n      <td>12.608571</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2512</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>111.360001</td>\n      <td>111.230003</td>\n    </tr>\n    <tr>\n      <th>2513</th>\n      <td>1</td>\n      <td>Fighting iOS Calendar Spam : Unsolicited invit...</td>\n      <td>111.129997</td>\n      <td>111.790001</td>\n    </tr>\n    <tr>\n      <th>2514</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>111.430000</td>\n      <td>111.570000</td>\n    </tr>\n    <tr>\n      <th>2515</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>110.779999</td>\n      <td>111.459999</td>\n    </tr>\n    <tr>\n      <th>2516</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>111.599998</td>\n      <td>110.519997</td>\n    </tr>\n  </tbody>\n</table>\n<p>2516 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding Missing Values\nmiss_value_row_list=[]\n\nfor j in range(len(data_new)):\n    if type(data_new[\"News\"][j]) is str: # Non-missing values will have str type\n        continue\n    else: \n        print( 'Row ' + str(j))\n        miss_value_row_list.append(j)\nmiss_value_row_list= list(set(miss_value_row_list)) # Removing repeating elements(row number) \nprint('\\n')\nprint(\"Row numbers with missing valus :\" + str(miss_value_row_list))","execution_count":5,"outputs":[{"output_type":"stream","text":"Row 1\nRow 6\nRow 13\nRow 42\nRow 47\nRow 57\nRow 62\nRow 77\nRow 81\nRow 83\nRow 122\nRow 128\nRow 135\nRow 141\nRow 159\nRow 168\nRow 184\nRow 213\nRow 221\nRow 254\nRow 258\nRow 265\nRow 270\nRow 278\nRow 290\nRow 297\nRow 316\nRow 320\nRow 328\nRow 351\nRow 367\nRow 372\nRow 379\nRow 393\nRow 399\nRow 417\nRow 425\nRow 434\nRow 453\nRow 463\nRow 467\nRow 472\nRow 479\nRow 482\nRow 503\nRow 511\nRow 519\nRow 521\nRow 525\nRow 531\nRow 572\nRow 584\nRow 612\nRow 618\nRow 625\nRow 633\nRow 647\nRow 652\nRow 670\nRow 682\nRow 689\nRow 696\nRow 699\nRow 703\nRow 711\nRow 731\nRow 736\nRow 749\nRow 772\nRow 775\nRow 794\nRow 834\nRow 835\nRow 857\nRow 871\nRow 899\nRow 919\nRow 942\nRow 959\nRow 972\nRow 978\nRow 987\nRow 1027\nRow 1035\nRow 1043\nRow 1047\nRow 1053\nRow 1065\nRow 1078\nRow 1088\nRow 1095\nRow 1107\nRow 1111\nRow 1121\nRow 1124\nRow 1130\nRow 1145\nRow 1151\nRow 1161\nRow 1168\nRow 1172\nRow 1179\nRow 1185\nRow 1195\nRow 1201\nRow 1208\nRow 1214\nRow 1222\nRow 1226\nRow 1231\nRow 1237\nRow 1243\nRow 1274\nRow 1296\nRow 1298\nRow 1301\nRow 1328\nRow 1380\nRow 1404\nRow 1430\nRow 1448\nRow 1480\nRow 1488\nRow 1509\nRow 1528\nRow 1547\nRow 1552\nRow 1582\nRow 1589\nRow 1616\nRow 1632\nRow 1674\nRow 1697\nRow 1717\nRow 1730\nRow 1760\nRow 1765\nRow 1778\nRow 1781\nRow 1799\nRow 1802\nRow 1821\nRow 1830\nRow 1836\nRow 1842\nRow 1890\nRow 1894\nRow 1925\nRow 1929\nRow 1947\nRow 1961\nRow 1964\nRow 1972\nRow 1989\nRow 2010\nRow 2032\nRow 2069\nRow 2093\nRow 2097\nRow 2118\nRow 2146\nRow 2178\nRow 2215\nRow 2220\nRow 2233\nRow 2284\nRow 2305\nRow 2309\nRow 2331\nRow 2348\nRow 2392\nRow 2410\nRow 2432\nRow 2434\nRow 2440\nRow 2450\nRow 2451\nRow 2452\nRow 2453\nRow 2456\nRow 2465\nRow 2469\nRow 2471\nRow 2472\nRow 2473\nRow 2485\nRow 2488\nRow 2493\nRow 2494\nRow 2499\nRow 2511\nRow 2513\nRow 2514\nRow 2515\n\n\nRow numbers with missing valus :[1, 1027, 6, 519, 521, 1035, 1547, 13, 525, 1552, 531, 1043, 2069, 1047, 1053, 1065, 42, 2093, 1582, 47, 2097, 1589, 1078, 57, 572, 62, 1088, 2118, 1095, 584, 77, 1616, 81, 83, 1107, 1111, 1632, 1121, 2146, 612, 1124, 618, 1130, 625, 633, 122, 1145, 1151, 128, 2178, 135, 647, 1161, 1674, 652, 141, 1168, 1172, 1179, 670, 159, 1185, 1697, 2215, 168, 682, 1195, 2220, 689, 1201, 1717, 184, 696, 1208, 699, 2233, 1214, 703, 1730, 1222, 711, 1226, 1231, 213, 1237, 731, 1243, 221, 736, 1760, 1765, 2284, 749, 1778, 1781, 1274, 254, 2305, 258, 772, 2309, 775, 1799, 265, 1802, 270, 1296, 1298, 1301, 278, 794, 2331, 1821, 290, 1830, 297, 1836, 2348, 1328, 1842, 316, 320, 834, 835, 328, 2392, 857, 351, 1890, 1380, 1894, 871, 2410, 367, 372, 379, 1404, 2432, 2434, 899, 1925, 2440, 393, 1929, 399, 2450, 2451, 2452, 2453, 1430, 919, 2456, 1947, 417, 2465, 2469, 2471, 1448, 425, 1961, 2472, 1964, 2473, 942, 434, 1972, 2485, 2488, 2493, 2494, 959, 2499, 453, 1989, 1480, 972, 463, 1488, 2511, 978, 467, 2513, 2514, 2515, 472, 2010, 987, 479, 482, 1509, 2032, 503, 1528, 511]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total Available Data:\nlen(data_new)-len(miss_value_row_list)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"2322"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing rows with missing entries\ndata_new.drop(miss_value_row_list, inplace = True)\n\n# Setting New Index for data\ndata_new= data_new.set_index(i for i in range(len(data_new)))","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(data_new.head())\ndisplay(data_new.tail())","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"   Label                                               News       Open  \\\n0      0  More on Housing Prices : The broadest governme...  13.125714   \n1      0  Honoring R.W. Apple in Words and Food : About ...  12.948571   \n2      0  Homebuilders, and Worries Over Jobs, Lead a De...  12.861428   \n3      1  Homebuilders, and Worries Over Jobs, Lead a De...  12.461429   \n4      1  Sales of iPods and iTunes Not Much in Sync : T...  12.700000   \n\n   Pre Adj Close  \n0      13.017143  \n1      12.832857  \n2      12.434286  \n3      12.608571  \n4      12.678572  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>News</th>\n      <th>Open</th>\n      <th>Pre Adj Close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>More on Housing Prices : The broadest governme...</td>\n      <td>13.125714</td>\n      <td>13.017143</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Honoring R.W. Apple in Words and Food : About ...</td>\n      <td>12.948571</td>\n      <td>12.832857</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Homebuilders, and Worries Over Jobs, Lead a De...</td>\n      <td>12.861428</td>\n      <td>12.434286</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Homebuilders, and Worries Over Jobs, Lead a De...</td>\n      <td>12.461429</td>\n      <td>12.608571</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Sales of iPods and iTunes Not Much in Sync : T...</td>\n      <td>12.700000</td>\n      <td>12.678572</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"      Label                                               News        Open  \\\n2317      0  Turn an iPad-Made Movie Into a DVD : Home vide...  109.809998   \n2318      1  When Eve and Eve Bit the Apple : A Christian w...  109.720001   \n2319      1  Daily Report: At Apple, U.S. Jobs That Go Beyo...  110.120003   \n2320      1  A Trade War Against China Might Be a Fight Tru...  111.949997   \n2321      1  Fighting iOS Calendar Spam : Unsolicited invit...  111.129997   \n\n      Pre Adj Close  \n2317     109.949997  \n2318     110.059998  \n2319     111.730003  \n2320     111.800003  \n2321     111.790001  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>News</th>\n      <th>Open</th>\n      <th>Pre Adj Close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2317</th>\n      <td>0</td>\n      <td>Turn an iPad-Made Movie Into a DVD : Home vide...</td>\n      <td>109.809998</td>\n      <td>109.949997</td>\n    </tr>\n    <tr>\n      <th>2318</th>\n      <td>1</td>\n      <td>When Eve and Eve Bit the Apple : A Christian w...</td>\n      <td>109.720001</td>\n      <td>110.059998</td>\n    </tr>\n    <tr>\n      <th>2319</th>\n      <td>1</td>\n      <td>Daily Report: At Apple, U.S. Jobs That Go Beyo...</td>\n      <td>110.120003</td>\n      <td>111.730003</td>\n    </tr>\n    <tr>\n      <th>2320</th>\n      <td>1</td>\n      <td>A Trade War Against China Might Be a Fight Tru...</td>\n      <td>111.949997</td>\n      <td>111.800003</td>\n    </tr>\n    <tr>\n      <th>2321</th>\n      <td>1</td>\n      <td>Fighting iOS Calendar Spam : Unsolicited invit...</td>\n      <td>111.129997</td>\n      <td>111.790001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data_new)","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"2322"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# NLP"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cleanig all the news(stacked together)\ndef nlp_preprocess(text):\n# corpus=[]\n    news= re.sub('[^a-zA-Z]', ' ', text)\n    news= news.lower()\n    news= news.split()\n    news=[word for word in news if not word in set(stopwords.words('english'))]\n    pe = PorterStemmer()\n    news=[pe.stem(word) for word in news if not word in set(stopwords.words('english'))]\n    news= ' '.join(news)\n    # corpus.append(news)\n    return news","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Target Variable\nY= data_new[\"Label\"].values\ndisplay(Y)\n\n# Input Variable\ntxt= data_new[\"News\"].values","execution_count":65,"outputs":[{"output_type":"display_data","data":{"text/plain":"array([0, 0, 0, ..., 1, 1, 1])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Spliting Dataset into Training and Test sets\nfrom sklearn.model_selection import train_test_split\nX_train_raw, X_test_raw, Y_train, Y_test= train_test_split(txt, Y, test_size=0.10, random_state=0)","execution_count":66,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train data\ntrain_corpus= []\nfor i in range(len(X_train_raw)):\n    train_corpus.append(nlp_preprocess(X_train_raw[i]))\n    \n# Test data\ntest_corpus= []\nfor i in range(len(X_test_raw)):\n    test_corpus.append(nlp_preprocess(X_test_raw[i]))","execution_count":67,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_model= joblib.load('../input/sentiment-material-3/cv_model.pkl')\n# Train data\ntrainX = cv_model.transform(train_corpus).toarray()\n\n# Test data\ntestX= cv_model.transform(test_corpus).toarray()","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sentiments + Open + Pre Adj Close\ndataset = pd.DataFrame()\n\n# open_price= []\n# for i in range(len(data_new)):\n#     open_price.append(data_new[\"Open\"][i]/10)\n    \n# previous_adj_close= []\n# for i in range(len(data_new)):\n#     previous_adj_close.append(data[\"Adj Close\"][i]/10)\n\n\n\n# Adding sentence sentiments\ntxt_sentiment= joblib.load('../input/sentiment-material-3/Txt_sentiment.pkl')\nneg= []\npos= []\nneu= []\n\n# Train data\nfor i in range(trainX.shape[0]):\n    pred= txt_sentiment.predict_proba(trainX[i].reshape(1, -1))\n    neg.append(pred[0][0])\n    pos.append(pred[0][1])\n    neu.append(pred[0][2])\n\n# Test data\nfor i in range(testX.shape[0]):\n    pred= txt_sentiment.predict_proba(testX[i].reshape(1, -1))\n    neg.append(pred[0][0])\n    pos.append(pred[0][1])\n    neu.append(pred[0][2])\n\ndataset.insert(0, \"Neg\", neg)\ndataset.insert(1, \"Pos\", pos)\ndataset.insert(2, \"Neu\", neu)\n# dataset.insert(3, \"Open\", open_price)\n# dataset.insert(4, \"Prev Adj Close\", previous_adj_close)\n\n#Spliting Dataset into Training and Test sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test= train_test_split(dataset, Y, test_size=0.10, random_state=0)\n\n#Feature Scaling\nfrom sklearn.preprocessing import MinMaxScaler\nsc_X= MinMaxScaler() \nX_train= sc_X.fit_transform(X_train)\nX_test= sc_X.transform(X_test)\n\njoblib.dump(sc_X, \"Feature_scaler.pkl\") # Saving the scaler for future use","execution_count":69,"outputs":[{"output_type":"execute_result","execution_count":69,"data":{"text/plain":"['Feature_scaler.pkl']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset","execution_count":70,"outputs":[{"output_type":"execute_result","execution_count":70,"data":{"text/plain":"               Neg       Pos           Neu\n0     2.688677e-06  0.050659  9.493380e-01\n1     6.460461e-06  0.000848  9.991457e-01\n2     2.378624e-01  0.762137  5.701936e-07\n3     1.996891e-08  0.000008  9.999923e-01\n4     1.270218e-08  0.000002  9.999978e-01\n...            ...       ...           ...\n2317  3.727986e-04  0.540203  4.594247e-01\n2318  8.735641e-02  0.912225  4.188772e-04\n2319  3.540883e-05  0.002528  9.974370e-01\n2320  4.471008e-03  0.269835  7.256940e-01\n2321  3.094768e-06  0.997243  2.753611e-03\n\n[2322 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Neg</th>\n      <th>Pos</th>\n      <th>Neu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.688677e-06</td>\n      <td>0.050659</td>\n      <td>9.493380e-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.460461e-06</td>\n      <td>0.000848</td>\n      <td>9.991457e-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.378624e-01</td>\n      <td>0.762137</td>\n      <td>5.701936e-07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.996891e-08</td>\n      <td>0.000008</td>\n      <td>9.999923e-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.270218e-08</td>\n      <td>0.000002</td>\n      <td>9.999978e-01</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2317</th>\n      <td>3.727986e-04</td>\n      <td>0.540203</td>\n      <td>4.594247e-01</td>\n    </tr>\n    <tr>\n      <th>2318</th>\n      <td>8.735641e-02</td>\n      <td>0.912225</td>\n      <td>4.188772e-04</td>\n    </tr>\n    <tr>\n      <th>2319</th>\n      <td>3.540883e-05</td>\n      <td>0.002528</td>\n      <td>9.974370e-01</td>\n    </tr>\n    <tr>\n      <th>2320</th>\n      <td>4.471008e-03</td>\n      <td>0.269835</td>\n      <td>7.256940e-01</td>\n    </tr>\n    <tr>\n      <th>2321</th>\n      <td>3.094768e-06</td>\n      <td>0.997243</td>\n      <td>2.753611e-03</td>\n    </tr>\n  </tbody>\n</table>\n<p>2322 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the data frame\ndataset.to_csv('Apple_Historic_News_Sentiment.csv',index=False)","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Spliting Dataset into Training and Test sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test= train_test_split(dataset, Y, test_size=0.10, random_state=0)","execution_count":72,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification Algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nclassifier= LogisticRegression(random_state= 0)\nclassifier.fit(X_train, Y_train)\n\n# Predicting the test set result\ny_pred= classifier.predict(X_test)\ndisplay(y_pred)\n\n# Making the Confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm= confusion_matrix(Y_test, y_pred)\ndisplay(cm)\n\nAccuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\ndisplay(Accuracy)","execution_count":73,"outputs":[{"output_type":"display_data","data":{"text/plain":"array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([[  8, 113],\n       [  8, 104]])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.48068669527896996"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree  \nfrom sklearn.tree import DecisionTreeClassifier\nclassifier= DecisionTreeClassifier(criterion= 'entropy', random_state= 0)\nclassifier.fit(X_train, Y_train)\n\n# Predicting the test set result\ny_pred= classifier.predict(X_test)\ndisplay(y_pred)\n\n# Making the Confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm= confusion_matrix(Y_test, y_pred)\ndisplay(cm)\n\nAccuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\ndisplay(Accuracy)","execution_count":74,"outputs":[{"output_type":"display_data","data":{"text/plain":"array([0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n       1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n       0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([[52, 69],\n       [45, 67]])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.5107296137339056"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gradient Boosting\nfrom sklearn.ensemble import GradientBoostingClassifier\nclassifier = GradientBoostingClassifier()\nclassifier = classifier.fit(X_train, Y_train)\n\n# Predicting the test set result\ny_pred= classifier.predict(X_test)\ndisplay(y_pred)\n\n# Making the Confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm= confusion_matrix(Y_test, y_pred)\ndisplay(cm)\n\nAccuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\ndisplay(Accuracy)","execution_count":75,"outputs":[{"output_type":"display_data","data":{"text/plain":"array([0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n       1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n       0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([[41, 80],\n       [37, 75]])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.4978540772532189"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Kernel SVM\nfrom sklearn.svm import SVC \nclassifier= SVC(kernel='rbf', random_state= 0)\nclassifier.fit(X_train, Y_train)\n\n# Predicting the test set result\ny_pred= classifier.predict(X_test)\ndisplay(y_pred)\n\n# Making the Confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm= confusion_matrix(Y_test, y_pred)\ndisplay(cm)\n\nAccuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\ndisplay(Accuracy)","execution_count":76,"outputs":[{"output_type":"display_data","data":{"text/plain":"array([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([[  9, 112],\n       [  5, 107]])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.4978540772532189"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Multinomial NB\nfrom sklearn.naive_bayes import MultinomialNB\nclassifier=MultinomialNB()\nclassifier.fit(X_train, Y_train)\n\n# Predicting the test set result\ny_pred= classifier.predict(X_test)\ndisplay(y_pred)\n\n# Making the Confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm= confusion_matrix(Y_test, y_pred)\ndisplay(cm)\n\nAccuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\ndisplay(Accuracy)","execution_count":77,"outputs":[{"output_type":"display_data","data":{"text/plain":"array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([[  0, 121],\n       [  0, 112]])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.48068669527896996"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier= KNeighborsClassifier(n_neighbors= 7, metric='minkowski', p=2, leaf_size=70, weights= 'distance', algorithm= 'brute')\nclassifier.fit(X_train, Y_train)\n\n# Predicting the test set result\ny_pred= classifier.predict(X_test)\ndisplay(y_pred)\n\n# Making the Confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm= confusion_matrix(Y_test, y_pred)\ndisplay(cm)\n\nAccuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\ndisplay(Accuracy)","execution_count":78,"outputs":[{"output_type":"display_data","data":{"text/plain":"array([0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n       1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([[51, 70],\n       [49, 63]])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.4892703862660944"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SGDC\nfrom sklearn.linear_model import SGDClassifier\nclassifier = SGDClassifier(loss='modified_huber', random_state=0)\nclassifier = classifier.fit(X_train, Y_train)\n\n# Predicting the test set result\ny_pred= classifier.predict(X_test)\ndisplay(y_pred)\n\n# Making the Confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm= confusion_matrix(Y_test, y_pred)\ndisplay(cm)\n\nAccuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\ndisplay(Accuracy)","execution_count":79,"outputs":[{"output_type":"display_data","data":{"text/plain":"array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([[121,   0],\n       [112,   0]])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.51931330472103"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier \nclassifier= RandomForestClassifier(n_estimators= 500, criterion= 'entropy', random_state= 0) # Try with diffrent numbers of n_estimators(n_estimators= number of trees)\nclassifier.fit(X_train, Y_train)\n\n# Predicting the test set result\ny_pred= classifier.predict(X_test)\ndisplay(y_pred)\n\n# Making the Confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm= confusion_matrix(Y_test, y_pred)\ndisplay(cm)\n\nAccuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\ndisplay(Accuracy)","execution_count":80,"outputs":[{"output_type":"display_data","data":{"text/plain":"array([0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n       1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n       0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([[54, 67],\n       [43, 69]])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.5278969957081545"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the classifier for future use \njoblib.dump(classifier, \"Historic_Apple_News_Sentiment.pkl\", compress= 1)","execution_count":81,"outputs":[{"output_type":"execute_result","execution_count":81,"data":{"text/plain":"['Historic_Apple_News_Sentiment.pkl']"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}